# -*- coding: utf-8 -*-
"""All_Features_Extracted

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13CN7JKczZw61TlfAUdRkUKg6EZKwr7YD
"""

import pandas as pd

# -1 = phishing
#  0 = suspicious
#  1 = legitimate


# Load the input CSV file
input_csv = "dataset_B_05_2020.csv"
output_csv = "REAL_DATASET_FINAL.csv"

# Read the CSV file into a DataFrame
df = pd.read_csv(input_csv)

# New columns
df['having_IP_Address'] = df['ip'].apply(lambda x: -1 if x == 1 else 1 if x == 0 else x)

df['URL_Length'] = df['length_url'].apply(
    lambda x: 1 if x < 54 else 0 if 54 <= x <= 75 else -1
)

df['Shortining_Service'] = df['shortening_service'].apply(
    lambda x: -1 if x == 1 else 1 if x == 0 else x
)

df['having_At_Symbol'] = df['nb_at'].apply(
    lambda x: -1 if x >= 1 else 1 if x == 0 else x
)

# used paper version for this part (we can explain later yay)
df['double_slash_redirecting'] = df['nb_dslash'].apply(
    lambda x: -1 if x >= 1 else 1 if x == 0 else x
)

df['Prefix_Suffix'] = df['prefix_suffix'].apply(
    lambda x: -1 if x == 1 else 1 if x == 0 else x
)

df['having_Sub_Domain'] = df['nb_subdomains'].apply(
    lambda x: 1 if x == 1 else 0 if x == 2 else -1
)

#WE SKIPPED 8 IN address bar features btw


def classify_domain_registration_length(expiry_days):
    if expiry_days <= 365:
        return -1
    else:
        return 1

df['Domain_Registeration_Length'] = df['domain_registration_length'].apply(classify_domain_registration_length)

df['Favicon'] = df['external_favicon'].apply(
    lambda x: -1 if x == 1 else 1 if x == 0 else x
)

#port is new
df['Port'] = df['port'].apply(
    lambda x: -1 if x == 1 else 1 if x == 0 else x
)

df['HTTPS_token'] = df['https_token'].apply(
    lambda x: 1 if x == 1 else -1 if x == 0 else x
)

#THIS ONE IS DIFFERENT TOO sort of
def extHyperlinks(ratio):
    if ratio <= 0.22:
        return 1
    elif ratio >0.22 and ratio <= 0.61:
        return 0
    else:
        return -1

df['Request_URL'] = df['ratio_extHyperlinks'].apply(extHyperlinks)

#dont know if they can do thid
#RATIO are like *100 so its their percent number not the number from 0 to 1
def urlanchor(ratio):
    ratio=1-0.01*ratio
    if ratio < 0.31:
        return 1
    elif 0.31 <= ratio <= 0.67:
        return 0
    else:
        return -1

df['Anchor_URL'] = df['safe_anchor'].apply(urlanchor)

def linkstags(ratio):
    ratio=1-0.01*ratio
    if ratio < 0.17:
        return 1
    elif ratio >= 0.17 and ratio <= 0.81:
        return 0
    else:
        return -1

df['Links_in_Tags'] = df['links_in_tags'].apply(linkstags)

# we removed Server Form Handler (SFH) because the training data has all 0s so it was kinda WTVVVVV

df['Abnormal_URL'] = df['whois_registered_domain'].apply(
    lambda x: 1 if x == 1 else -1 if x == 0 else x
)

#we decided to change website forwarding to hyperlinks because it is in the top few features for the 3 diff filters? TABLE 6 PAPER
#we r gonna do later its pissing me off UGH NEED TO FIND A FUCKING THRESHOLD

#taking status bar customization out too the mouseover attribute
#taking out most of the HTML and JavaScript based Features but we still use ratio of eternal hyperlinks


def classifydomainage(days):
    if days >= 180:
        return 1
    else:
        return -1

df['Domain_age'] = df['domain_age'].apply(classifydomainage)

df['DNS_record'] = df['dns_record'].apply(
    lambda x: 1 if x == 1 else -1 if x == 0 else x
)

def classifytraffic(visitors):
    if visitors > 1000000:
        return 0
    elif visitors <= 1000000 and visitors > 0:
        return 1
    else:
        return -1

df['Website_traffic'] = df['web_traffic'].apply(classifytraffic)

def classifypr(pr):
    if pr < 2:
        return -1
    else:
        return 1

df['Page_rank'] = df['page_rank'].apply(classifypr)

df['Google_Index'] = df['google_index'].apply(
    lambda x: 1 if x == 1 else -1 if x == 0 else x
)

columns_to_keep = ['having_IP_Address', 'URL_Length', 'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix', 'having_Sub_Domain', 'Domain_Registeration_Length', 'Favicon', 'Port', 'HTTPS_token', 'Request_URL', 'Anchor_URL', 'Links_in_Tags', 'Abnormal_URL', 'Domain_age', 'DNS_record', 'Website_traffic', 'Page_rank', 'Google_Index', 'status' ]  # List of new columns
df = df[columns_to_keep]

# Save the modified DataFrame to a new CSV file
df.to_csv(output_csv, index=False)

print(f"Transformed CSV saved to {output_csv}")

